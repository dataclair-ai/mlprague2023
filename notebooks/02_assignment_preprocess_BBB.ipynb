{"cells":[{"cell_type":"markdown","source":["## Data\n","- Lets have a look at our dataset, preprocess it and save the preprocessed version"],"metadata":{"id":"ADbxKqxoMy-X"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USVBwqaoM_4v","outputId":"292bce77-a19c-49d4-99e5-97f41af3b2e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRaBDgV8Mwkz"},"outputs":[],"source":["import re\n","import pandas as pd\n","\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ygh-zIPbMwk4"},"outputs":[],"source":["# dataset comes from here: https://github.com/theochem/B3DB/blob/main/README.md\n","\n","df = pd.read_csv(\"https://staicentreprod001.blob.core.windows.net/share/mlprague23/B3DB_classification.tsv\", sep=\"\\t\")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fF4LyGtMwk6"},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIMidRrwMwk9"},"outputs":[],"source":["# for readability\n","df = df.rename(columns={\"BBB+/BBB-\": \"label\", \"compound_name\": \"name\"})\n","df.loc[df.label == \"BBB+\", \"label\"] = 1\n","df.loc[df.label == \"BBB-\", \"label\"] = 0\n","\n","df.head(20)"]},{"cell_type":"markdown","metadata":{"id":"6XJYfCGfMwlA"},"source":["### Do the molecule names need to be cleaned?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kx7kcl6SMwlE"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOJfwPw2MwlG"},"outputs":[],"source":["mol_ids = tokenizer.encode('bbcpd11 (cimetidine analog) (y-g13)')\n","print('mol_ids:', mol_ids)\n","\n","print('mol_tokens', tokenizer.convert_ids_to_tokens(mol_ids))"]},{"cell_type":"markdown","source":["- Notice how the subword unit (suffix) starts with \"##\" to indicate that it is part of the previous string\n","- Also [CLS] and [SEP] tokens are automatically added"],"metadata":{"id":"7yLdKaGGBYWR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dqcto0qrMwlJ"},"outputs":[],"source":["mol_ids = tokenizer.encode('morphine-6-glucuronide')\n","print('mol_ids:', mol_ids)\n","print('mol_tokens', tokenizer.convert_ids_to_tokens(mol_ids))"]},{"cell_type":"markdown","source":["- The model has *morphine* and *glucuronide* in its vocabulary (has matching input id for these words)\n","- But doesn't have *bbcpd11* or *cimetidine*"],"metadata":{"id":"9HbDC4sdBv-2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ciz3lqwXMwlL"},"outputs":[],"source":["mol_ids = tokenizer.encode('33419-42-0')\n","print('mol_ids:', mol_ids)\n","print('mol_tokens', tokenizer.convert_ids_to_tokens(mol_ids))"]},{"cell_type":"markdown","metadata":{"id":"VZ2ckDzgMwlV"},"source":["#### Regex to remove non alpha-numeric characters and convert to lowercase\n","- see it in action: https://regex101.com/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDO-0njHMwlX"},"outputs":[],"source":["df[\"name\"] = df[\"name\"].apply(lambda x: re.sub(\"[^A-Za-z0-9]+\", \"\", str(x)).lower())\n","df.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8bN8vimMwlY"},"outputs":[],"source":["# replace molecules whose names are just numbers with nan\n","df[\"name\"] = df[\"name\"].apply(lambda x: re.sub(\"^[0-9]+\", \"nan\", str(x)))\n","df.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KytRUeeUMwla"},"outputs":[],"source":["df[df[\"name\"] == \"nan\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D_l5FqZeMwlb"},"outputs":[],"source":["num_nan=sum(df[\"name\"] == \"nan\")\n","print(f\"number of molecules with nan name: {num_nan}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rLeFLjwMwlc"},"outputs":[],"source":["print(f\"df shape before nan molecule removal: {df.shape}\")\n","df = df[df[\"name\"] != \"nan\"]\n","print(f\"df shape after nan molecule removal: {df.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjv0AOuLMwld"},"outputs":[],"source":["df.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0OpsHQoMwle"},"outputs":[],"source":["df = df.drop_duplicates(subset=\"name\")\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZipJpcGMwlf"},"outputs":[],"source":["# make train-test split of data using name column as X data and label as y data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3vh9LylMwlg"},"outputs":[],"source":["df.name.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUd00tdrMwlh"},"outputs":[],"source":["df_train = pd.DataFrame(data={\"name\": X_train, \"label\": y_train})\n","\n","df_test = pd.DataFrame(data={\"name\": X_test, \"label\": y_test})"]},{"cell_type":"markdown","source":["Mount your drive to colab so you can write the processed data there"],"metadata":{"id":"kN-HQ1ApD68D"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"2ZnSrf5CPkh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsMw5OaXMwli"},"outputs":[],"source":["# save preprocessed data to your drive \n"]},{"cell_type":"markdown","source":["Split and save dataset with SMILES separately"],"metadata":{"id":"DzxfXmIGED-I"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HZSXCYZMwlj"},"outputs":[],"source":["# repeat what was done above using name column but now for SMILES, and save the data :)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vVbBu8iMwll"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"QugbC_1fNajU"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"1BKhKy5M8W7FDbm_WW-VxHXxedTDW1DCN","timestamp":1685608060077}]}},"nbformat":4,"nbformat_minor":0}